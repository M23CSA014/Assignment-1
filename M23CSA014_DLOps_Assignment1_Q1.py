# -*- coding: utf-8 -*-
"""M23CSA014_DLOps_Assignment1_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IYPAqPKWY8M5f9oRxXzgLy_RFswxmxav
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset

from sklearn.datasets import load_iris
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
# from sklearn.metrics import UndefinedMetricWarning


import seaborn as sns
import torch.nn.functional as F
import torchvision.transforms as transforms

from torch.utils.tensorboard import SummaryWriter
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import numpy as np

import torchvision
import warnings

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir /content/runs

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print("Device:", device)

"""Data preprocessing"""

# Custom Iris dataset class
class IrisDataset(Dataset):
    def __init__(self, data, target):
        self.data = torch.tensor(data, dtype=torch.float32)
        self.target = torch.tensor(target)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx], self.target[idx]

# Load Iris data
iris = load_iris()
data = iris.data
target = iris.target
print(target)

"""Model Architecture"""

class Architecture(nn.Module):
    def __init__(self):
        super(Architecture, self).__init__()
        self.fc1 = nn.Linear(4, 5)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(5, 7)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(7, 3)  # Output layer with 3 classes

    def forward(self, x):
        x = self.relu1(self.fc1(x))
        x = self.relu2(self.fc2(x))
        y = x
        x = F.softmax(self.fc3(x), dim=1)  # Softmax for probability
        return x, y

def train_model(model, train_loader, val_loader, criterion, optimizer, writer, fold):
    for epoch in range(25):
        model.train()
        train_loss = 0.0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs, _ = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * inputs.size(0)

        train_loss /= len(train_loader.dataset)

        # print(f'Epoch {epoch+1}/{5}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')
        # print(f'{optimizer_type}, {lr} lr, {i} fold, Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}, Training Accuracy: {train_acc}')

        model.eval()
        val_loss = 0.0
        val_preds = []
        val_targets = []

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs, _ = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)

                val_preds.extend(preds.tolist())
                val_targets.extend(labels.tolist())

        val_loss /= len(val_loader.dataset)

        val_accuracy = accuracy_score(val_targets, val_preds)
        val_precision = precision_score(val_targets, val_preds, average='macro')
        val_recall = recall_score(val_targets, val_preds, average='macro')

        print(f'Fold: {fold + 1}, Epoch: {epoch + 1}, '
              f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '
              f'Val Accuracy: {val_accuracy*100:.4f}, '
              f'Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}')

        # Write metrics to Tensorboard
        writer.add_scalar('Loss/train', train_loss, fold * 100 + epoch)
        writer.add_scalar('Loss/validation', val_loss, fold * 100 + epoch)
        writer.add_scalar('Accuracy/validation', val_accuracy, fold * 100 + epoch)
        writer.add_scalar('Precision/validation', val_precision, fold * 100 + epoch)
        writer.add_scalar('Recall/validation', val_recall, fold * 100 + epoch)

def generate_tsne_plot(model, X_val, y_val, writer, fold):
    model.eval()
    with torch.no_grad():
        _, outputs = model(torch.tensor(X_val, dtype=torch.float32))
        features = outputs.numpy()
        tsne = TSNE(n_components=2, perplexity=min(10, X_val.shape[0] - 1))
        tsne_result = tsne.fit_transform(features)

        plt.figure(figsize=(8, 6))
        for i in range(3):
            plt.scatter(tsne_result[y_val == i, 0], tsne_result[y_val == i, 1], label=f'Class {i}')
        plt.title(f'T-SNE Plot - Fold {fold + 1}')
        plt.legend()
        plt.show()
        writer.add_figure(f'T-SNE/Fold_{fold + 1}', plt.gcf())

        #  # Suppress warnings for precision being ill-defined
        # with warnings.catch_warnings():
        #     warnings.filterwarnings("ignore", category=UndefinedMetricWarning)
        #     val_precision = precision_score(y_val, model(torch.tensor(X_val, dtype=torch.float32)).argmax(dim=1), average='macro', zero_division=0)
        #     writer.add_scalar('Precision/validation', val_precision, fold)

def run_cross_validation(X, y):
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    writer = SummaryWriter()

    for fold, (train_index, val_index) in enumerate(kf.split(X)):
        X_train, X_val = X[train_index], X[val_index]
        y_train, y_val = y[train_index], y[val_index]

        train_dataset = IrisDataset(X_train, y_train)
        val_dataset = IrisDataset(X_val, y_val)

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32)

        model = Architecture()
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.005)

        train_model(model, train_loader, val_loader, criterion, optimizer, writer, fold)
        generate_tsne_plot(model, X, y, writer, fold)

    writer.close()

# Run cross-validation
run_cross_validation(data, target)